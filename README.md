
# neural-rendering-starter  
**CSâ€¯445 â€“â€¯Kibaeâ€¯Kim (kibaek2)**

A minimal but endâ€‘toâ€‘end pipeline for learning and rendering **3â€‘D Gaussian Splatting** on the classic **NeRFâ€‘syntheticâ€¯â€œlegoâ€** scene.  
Everything is pure PyTorch; no external C++/CUDA kernels are required.

---

## ğŸ“‚ Directory layout (after clone)

```

neural-rendering-starter/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ gaussian\_train.yaml      # training hyperâ€‘params
â”œâ”€â”€ data/
â”‚   â””â”€â”€ nerf\_synthetic/
â”‚       â””â”€â”€ lego/
â”‚           â”œâ”€â”€ images/          # 200 RGB input frames  (r\_0.png â€¦ r\_199.png)
â”‚           â””â”€â”€ colmap\_output/   # sparse COLMAP model (cameras.txt, images.txt, points3D.txt | .bin)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gaussian/
â”‚   â”‚   â”œâ”€â”€ **init**.py
â”‚   â”‚   â”œâ”€â”€ gaussian\_point.py
â”‚   â”‚   â””â”€â”€ init\_from\_sfm.py
â”‚   â”œâ”€â”€ render.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ **init**.py
â””â”€â”€ requirements.txt

````

### Where did the **lego** data come from?

| Folder | Origin | Notes |
|--------|--------|-------|
| `images/` | [NeRFâ€‘synthetic dataset](https://github.com/bmild/nerf) â€“â€¯**lego** scene, converted to 800Ã—800 PNG | Licensing: Creative Commons BYâ€‘SAâ€‘4.0 (same as original NeRF repo) |
| `colmap_output/` | Generated **offline** with COLMAP 3.8:<br>`colmap automatic_reconstructor â€¦` | Preâ€‘computed so that Colab users donâ€™t need to run COLMAP (â‰ˆâ€¯minutes).<br>Both `.txt` and `.bin` formats are accepted. |

If you want to rebuild these files yourself, see `scripts/convert_colmap.py` or run COLMAP on the `images/` folder.

---

## ğŸ› Â Installation

```bash
git clone https://github.com/<yourâ€‘github>/neural-rendering-starter.git
cd neural-rendering-starter
pip install -r requirements.txt
````

*Default `requirements.txt` assumes CUDAÂ 11.8 wheels.  Adjust versions if your GPU/driver is older.*

---

## ğŸš€Â Training (single GPU or Colab)


https://colab.research.google.com/drive/1-FKB89IfXQunT8GlKgti-ktlwxYejFoW#scrollTo=g3fCCwIqtVua

```bash
# fresh run
python src/train.py --cfg configs/gaussian_train.yaml

# resume from a checkpoint
python src/train.py --cfg configs/gaussian_train.yaml \
                    --resume output/exp1/epoch010.pt
```

* Checkpoints (`epochXXX.pt`) and preview renders (`renderXXX.png`) are written to `output/exp1/` every `save_every` epochs.
* Mixedâ€‘precision (AMP) is on automatically if CUDA is available.

---

## âœ¨Â Preview / Evaluation (optional)

```bash
# render a 360Â° camera path once training is done
python src/infer.py --ckpt output/exp1/epoch100.pt \
                    --camera_path data/camera_path.json
```

---

## ğŸ“Â Requirements

Installed automatically via **requirements.txt**:

* `torch`,Â `torchvision`
* `numpy`,Â `Pillow`,Â `PyYAML`
* `imageio`,Â `tqdm`
* *(optional)* `pycolmap` â€“ only if you need BINâ†’TXT conversion inside Colab

---

## ğŸ”–Â Citation / Credits

* **NeRFâ€‘synthetic dataset** â€“ BenÂ MildenhallÂ etÂ al., *ECCVÂ 2020*
* **COLMAP** â€“ JohannesÂ L.Â SchÃ¶nbergerÂ etâ€¯al.
* **3â€‘D Gaussian Splatting** â€“ KerblÂ etÂ al., *SIGGRAPHÂ AsiaÂ 2023*

---

